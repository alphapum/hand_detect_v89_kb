{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pyautogui\n",
    "\n",
    "# MediaPipe hand detection module\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "# OpenCV video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Screen resolution\n",
    "screen_width, screen_height = pyautogui.size()\n",
    "\n",
    "# Create a hands object\n",
    "with mp_hands.Hands(\n",
    "    static_image_mode=False,\n",
    "    max_num_hands=2,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5) as hands:\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Flip the frame horizontally\n",
    "        frame = cv2.flip(frame, 1)\n",
    "\n",
    "        # Process the frame with MediaPipe\n",
    "        results = hands.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                # Get the landmarks of the index finger and middle finger\n",
    "                index_finger_tip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "                middle_finger_tip = hand_landmarks.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_TIP]\n",
    "\n",
    "                # Convert the normalized coordinates to screen coordinates\n",
    "                index_x = int(index_finger_tip.x * screen_width)\n",
    "                index_y = int(index_finger_tip.y * screen_height)\n",
    "                middle_x = int(middle_finger_tip.x * screen_width)\n",
    "                middle_y = int(middle_finger_tip.y * screen_height)\n",
    "\n",
    "                # Check if the middle finger tip is close to the index finger tip\n",
    "                if middle_finger_tip.y > index_finger_tip.y:\n",
    "                    # Perform a left click at the index finger position\n",
    "                    pyautogui.leftClick(index_x, index_y)\n",
    "                else:\n",
    "                    # Move the mouse cursor to the middle finger position\n",
    "                    pyautogui.moveTo(middle_x, middle_y)\n",
    "\n",
    "                # Draw hand landmarks on the frame\n",
    "                mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "        # Display the resulting frame\n",
    "        cv2.imshow('Hand Click and Move', frame)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pyautogui\n",
    "\n",
    "# MediaPipe hand detection module\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "# OpenCV video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Screen resolution\n",
    "screen_width, screen_height = pyautogui.size()\n",
    "\n",
    "# Create a hands object\n",
    "with mp_hands.Hands(\n",
    "    static_image_mode=False,\n",
    "    max_num_hands=2,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5) as hands:\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Flip the frame horizontally\n",
    "        frame = cv2.flip(frame, 1)\n",
    "\n",
    "        # Process the frame with MediaPipe\n",
    "        results = hands.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                # Get the landmarks of the index finger, middle finger, ring finger, and pinky finger\n",
    "                index_finger_tip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "                middle_finger_tip = hand_landmarks.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_TIP]\n",
    "                ring_finger_tip = hand_landmarks.landmark[mp_hands.HandLandmark.RING_FINGER_TIP]\n",
    "                pinky_finger_tip = hand_landmarks.landmark[mp_hands.HandLandmark.PINKY_TIP]\n",
    "\n",
    "                # Convert the normalized coordinates to screen coordinates\n",
    "                index_x = int(index_finger_tip.x * screen_width)\n",
    "                index_y = int(index_finger_tip.y * screen_height)\n",
    "                middle_x = int(middle_finger_tip.x * screen_width)\n",
    "                middle_y = int(middle_finger_tip.y * screen_height)\n",
    "                ring_x = int(ring_finger_tip.x * screen_width)\n",
    "                ring_y = int(ring_finger_tip.y * screen_height)\n",
    "                pinky_x = int(pinky_finger_tip.x * screen_width)\n",
    "                pinky_y = int(pinky_finger_tip.y * screen_height)\n",
    "\n",
    "                # Check for left-click: index finger and middle finger extended\n",
    "                if middle_finger_tip.y < index_finger_tip.y:\n",
    "                    pyautogui.moveTo(index_x, index_y)\n",
    "                    pyautogui.mouseDown()\n",
    "                    pyautogui.mouseUp()\n",
    "\n",
    "                # Check for right-click: ring finger and index finger extended\n",
    "                if index_finger_tip.y < ring_finger_tip.y:\n",
    "                    pyautogui.moveTo(ring_x, ring_y)\n",
    "                    pyautogui.mouseDown(button='right')\n",
    "                    pyautogui.mouseUp(button='right')\n",
    "\n",
    "                # Move the mouse cursor with the pointer finger\n",
    "                pyautogui.moveTo(index_x, index_y)\n",
    "\n",
    "                # Draw hand landmarks on the frame\n",
    "                mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "        # Display the resulting frame\n",
    "        cv2.imshow('Hand Click and Move', frame)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pointer only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'HandLandmark' object has no attribute 'landmark'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 44\u001b[0m\n\u001b[0;32m     41\u001b[0m         pyautogui\u001b[39m.\u001b[39mmoveTo(index_x, index_y)\n\u001b[0;32m     43\u001b[0m         \u001b[39m# Draw hand landmarks on the frame\u001b[39;00m\n\u001b[1;32m---> 44\u001b[0m         mp_drawing\u001b[39m.\u001b[39;49mdraw_landmarks(frame,mp_hands\u001b[39m.\u001b[39;49mHandLandmark\u001b[39m.\u001b[39;49mINDEX_FINGER_TIP, hand_landmarks, mp_hands\u001b[39m.\u001b[39;49mHAND_CONNECTIONS)\n\u001b[0;32m     46\u001b[0m \u001b[39m# Display the resulting frame\u001b[39;00m\n\u001b[0;32m     47\u001b[0m cv2\u001b[39m.\u001b[39mimshow(\u001b[39m'\u001b[39m\u001b[39mHand Mouse Move\u001b[39m\u001b[39m'\u001b[39m, frame)\n",
      "File \u001b[1;32mc:\\Users\\PP\\.virtualenvs\\Hand_Detection-GuvXzzGQ\\lib\\site-packages\\mediapipe\\python\\solutions\\drawing_utils.py:157\u001b[0m, in \u001b[0;36mdraw_landmarks\u001b[1;34m(image, landmark_list, connections, landmark_drawing_spec, connection_drawing_spec)\u001b[0m\n\u001b[0;32m    155\u001b[0m image_rows, image_cols, _ \u001b[39m=\u001b[39m image\u001b[39m.\u001b[39mshape\n\u001b[0;32m    156\u001b[0m idx_to_coordinates \u001b[39m=\u001b[39m {}\n\u001b[1;32m--> 157\u001b[0m \u001b[39mfor\u001b[39;00m idx, landmark \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(landmark_list\u001b[39m.\u001b[39;49mlandmark):\n\u001b[0;32m    158\u001b[0m   \u001b[39mif\u001b[39;00m ((landmark\u001b[39m.\u001b[39mHasField(\u001b[39m'\u001b[39m\u001b[39mvisibility\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mand\u001b[39;00m\n\u001b[0;32m    159\u001b[0m        landmark\u001b[39m.\u001b[39mvisibility \u001b[39m<\u001b[39m _VISIBILITY_THRESHOLD) \u001b[39mor\u001b[39;00m\n\u001b[0;32m    160\u001b[0m       (landmark\u001b[39m.\u001b[39mHasField(\u001b[39m'\u001b[39m\u001b[39mpresence\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mand\u001b[39;00m\n\u001b[0;32m    161\u001b[0m        landmark\u001b[39m.\u001b[39mpresence \u001b[39m<\u001b[39m _PRESENCE_THRESHOLD)):\n\u001b[0;32m    162\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'HandLandmark' object has no attribute 'landmark'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pyautogui\n",
    "\n",
    "# MediaPipe hand detection module\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "# OpenCV video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Screen resolution\n",
    "screen_width, screen_height = pyautogui.size()\n",
    "\n",
    "# Create a hands object\n",
    "with mp_hands.Hands(\n",
    "    static_image_mode=False,\n",
    "    max_num_hands=2,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5) as hands:\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Flip the frame horizontally\n",
    "        frame = cv2.flip(frame, 1)\n",
    "\n",
    "        # Process the frame with MediaPipe\n",
    "        results = hands.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                # Get the landmark of the index finger\n",
    "                index_finger_tip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "\n",
    "                # Convert the normalized coordinates to screen coordinates\n",
    "                index_x = int(index_finger_tip.x * screen_width)\n",
    "                index_y = int(index_finger_tip.y * screen_height)\n",
    "\n",
    "                # Move the mouse cursor with the index finger (pointer)\n",
    "                pyautogui.moveTo(index_x, index_y)\n",
    "\n",
    "                # Draw hand landmarks on the frame\n",
    "                mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "        # Display the resulting frame\n",
    "        cv2.imshow('Hand Mouse Move', frame)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pointer and color\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pyautogui\n",
    "\n",
    "# MediaPipe hand detection module\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "\n",
    "\n",
    "# Screen resolution\n",
    "screen_width, screen_height = pyautogui.size()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sub Function Movement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_cursor(x, y):\n",
    "    # Move the mouse cursor to the given coordinates\n",
    "    pyautogui.moveTo(x, y)\n",
    "\n",
    "def draw_index_finger_tip(frame, hand_landmarks):\n",
    "    # Get the landmark of the index finger tip\n",
    "    # index_x =0\n",
    "    # index_y =0\n",
    "\n",
    "    if hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP].y < hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_PIP].y and \\\n",
    "      hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_PIP].y < hand_landmarks.landmark[mp_hands.HandLandmark.PINKY_TIP].y : \n",
    "          \n",
    "        index_finger_tip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "\n",
    "    # Convert the normalized coordinates to screen coordinates\n",
    "        index_x = int(index_finger_tip.x * screen_width)\n",
    "        index_y = int(index_finger_tip.y * screen_height)\n",
    "\n",
    "        # Draw the index finger tip on the frame in green color\n",
    "        mp_drawing.draw_landmarks(\n",
    "            frame,hand_landmarks,\n",
    "            \n",
    "            mp_hands.HAND_CONNECTIONS,\n",
    "            \n",
    "                mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=2),\n",
    "                # mp_drawing.DrawingSpec(color=(0, 0, 0), thickness=2),\n",
    "                # [mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "\n",
    "        )\n",
    "        print(index_x, index_y)\n",
    "\n",
    "        return index_x, index_y\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    else:\n",
    "        mp_drawing.draw_landmarks(\n",
    "            frame,hand_landmarks,\n",
    "            \n",
    "            mp_hands.HAND_CONNECTIONS,\n",
    "            \n",
    "                mp_drawing.DrawingSpec(color=(255, 0, 0), thickness=2, circle_radius=2),\n",
    "                # mp_drawing.DrawingSpec(color=(0, 0, 0), thickness=2),\n",
    "                # [mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "\n",
    "        )\n",
    "\n",
    "        return 1055 , 798 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hand_landmarks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m(hand_landmarks\u001b[39m.\u001b[39mlandmark[mp_hands\u001b[39m.\u001b[39mHandLandmark\u001b[39m.\u001b[39mINDEX_FINGER_TIP]\u001b[39m.\u001b[39my)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'hand_landmarks' is not defined"
     ]
    }
   ],
   "source": [
    "# print(hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP].y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HandLandmark.INDEX_FINGER_TIP\n"
     ]
    }
   ],
   "source": [
    "print(mp_hands.HandLandmark.INDEX_FINGER_TIP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Feame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_frame(frame):\n",
    "    # Flip the frame horizontally\n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    # Process the frame with MediaPipe\n",
    "    results = hands.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        if results.multi_handedness[0].classification[0].label == 'Left' :\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                # Move the mouse cursor with the index finger tip (pointer)\n",
    "                index_x, index_y = draw_index_finger_tip(frame, hand_landmarks)\n",
    "                move_cursor(index_x, index_y)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Hand Mouse Move', frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "950 364\n",
      "946 354\n",
      "942 350\n",
      "942 350\n",
      "941 347\n",
      "940 345\n",
      "948 343\n",
      "945 345\n",
      "942 346\n",
      "944 345\n",
      "964 350\n",
      "1098 391\n",
      "1148 413\n",
      "1043 406\n",
      "988 395\n",
      "967 387\n",
      "961 379\n",
      "976 365\n",
      "970 354\n",
      "975 353\n",
      "978 350\n",
      "971 347\n",
      "956 343\n",
      "950 341\n",
      "940 331\n",
      "909 314\n",
      "923 323\n",
      "978 319\n",
      "990 315\n",
      "1019 315\n",
      "1065 317\n",
      "1065 319\n",
      "1053 322\n",
      "1044 321\n",
      "1046 323\n",
      "1038 329\n",
      "1044 364\n",
      "1072 379\n",
      "1096 387\n",
      "1166 401\n",
      "1174 403\n",
      "1176 411\n",
      "1177 411\n",
      "1141 387\n",
      "1133 384\n",
      "1135 382\n",
      "1132 382\n",
      "1100 377\n",
      "1100 375\n",
      "1099 377\n",
      "1089 376\n",
      "1086 375\n",
      "1083 376\n",
      "1078 378\n",
      "1076 378\n",
      "1074 379\n",
      "1060 377\n",
      "1055 374\n",
      "1059 372\n",
      "1062 376\n",
      "1066 377\n",
      "1082 382\n",
      "1104 392\n",
      "1202 419\n",
      "1284 441\n",
      "1395 474\n",
      "1492 510\n",
      "1350 472\n",
      "1075 365\n",
      "1091 369\n",
      "954 325\n",
      "909 328\n",
      "917 337\n",
      "944 340\n",
      "981 349\n",
      "1027 369\n",
      "1088 393\n",
      "1182 428\n",
      "1191 432\n",
      "1184 429\n",
      "1183 422\n",
      "1189 396\n",
      "1259 328\n",
      "1373 367\n",
      "1385 424\n",
      "1183 371\n",
      "1192 366\n",
      "1156 390\n"
     ]
    }
   ],
   "source": [
    "# OpenCV video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Create a hands object\n",
    "with mp_hands.Hands(\n",
    "    static_image_mode=False,\n",
    "    max_num_hands=2,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5) as hands:\n",
    "\n",
    "\n",
    "    # Main program loop\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        process_frame(frame)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Hand_Detection-GuvXzzGQ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
