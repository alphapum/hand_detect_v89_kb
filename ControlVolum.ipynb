{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pyautogui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import math\n",
    "import pyautogui\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MediaPipe hand detection module\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "# OpenCV video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Create a hands object\n",
    "with mp_hands.Hands(\n",
    "    static_image_mode=False,\n",
    "    max_num_hands=2,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5) as hands:\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Process the frame with MediaPipe\n",
    "        results = hands.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                # Get the landmarks of the thumb and index finger\n",
    "                thumb_tip = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP]\n",
    "                index_finger_tip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "\n",
    "                # Calculate the Euclidean distance between thumb and index finger\n",
    "                distance = math.sqrt(\n",
    "                    (thumb_tip.x - index_finger_tip.x) ** 2 + (thumb_tip.y - index_finger_tip.y) ** 2)\n",
    "\n",
    "                # Map the distance to volume range (0-100)\n",
    "                volume = int((distance * 100) / 0.4)  # Adjust the scaling factor as needed\n",
    "\n",
    "                # Set the system volume\n",
    "                pyautogui.press('volumedown') if volume < 50 else pyautogui.press('volumeup')\n",
    "\n",
    "                # Display the volume level on the frame\n",
    "                cv2.putText(frame, f\"Volume: {volume}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
    "                \n",
    "                # Draw hand landmarks on the frame\n",
    "                mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "        # Display the resulting frame\n",
    "        cv2.imshow('Finger Volume Control', frame)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Right hand only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MediaPipe hand detection module\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "# OpenCV video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "# Create a hands object\n",
    "with mp_hands.Hands(\n",
    "    static_image_mode=False,\n",
    "    max_num_hands=2,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5) as hands:\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Flip the frame horizontally\n",
    "        frame = cv2.flip(frame, 1)\n",
    "\n",
    "        # Process the frame with MediaPipe\n",
    "        results = hands.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                # Get the bounding box coordinates\n",
    "                x_min = min(lm.x for lm in hand_landmarks.landmark)\n",
    "                x_max = max(lm.x for lm in hand_landmarks.landmark)\n",
    "                y_min = min(lm.y for lm in hand_landmarks.landmark)\n",
    "                y_max = max(lm.y for lm in hand_landmarks.landmark)\n",
    "\n",
    "                # Calculate the width and height of the bounding box\n",
    "                width = x_max - x_min\n",
    "                height = y_max - y_min\n",
    "\n",
    "                # Consider only the right hand based on the bounding box\n",
    "                if width > 0.3 and height > 0.3:\n",
    "\n",
    "                    # Get the landmarks of the thumb and index finger\n",
    "                    thumb_tip = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP]\n",
    "                    index_finger_tip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "\n",
    "                    # Calculate the Euclidean distance between thumb and index finger\n",
    "                    distance = math.sqrt(\n",
    "                        (thumb_tip.x - index_finger_tip.x) ** 2 + (thumb_tip.y - index_finger_tip.y) ** 2)\n",
    "\n",
    "                    # Map the distance to volume range (0-100)\n",
    "                    volume = int((distance * 100) / 0.3)  # Adjust the scaling factor as needed\n",
    "\n",
    "                    # Set the system volume\n",
    "                    pyautogui.press('volumedown') if volume < 50 else pyautogui.press('volumeup')\n",
    "\n",
    "                    # Display the volume level on the frame\n",
    "                    cv2.putText(frame, f\"Volume: {volume}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
    "\n",
    "                    # Draw lines between fingers\n",
    "                    cv2.line(frame, (int(thumb_tip.x * frame.shape[1]), int(thumb_tip.y * frame.shape[0])),\n",
    "                             (int(index_finger_tip.x * frame.shape[1]), int(index_finger_tip.y * frame.shape[0])),\n",
    "                             (0, 255, 0), 2)\n",
    "\n",
    "                    # Draw hand landmarks on the frame\n",
    "                    mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "        # Display the resulting frame\n",
    "        cv2.imshow('Finger Volume Control', frame)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use libraly CTYPES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pycaw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ctypes import cast, POINTER\n",
    "from comtypes import CLSCTX_ALL\n",
    "from pycaw.pycaw import AudioUtilities, IAudioEndpointVolume\n",
    "devices = AudioUtilities.GetSpeakers()\n",
    "interface = devices.Activate(\n",
    "    IAudioEndpointVolume._iid_, CLSCTX_ALL, None)\n",
    "volume = cast(interface, POINTER(IAudioEndpointVolume))\n",
    "# volume.GetMute()\n",
    "# volume.GetMasterVolumeLevel(  1)\n",
    "# volume.GetVolumeRange( 0.0, 0.75)\n",
    "# volume.SetMasterVolumeLevel(-20.0, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_volume( volume_level):\n",
    "    devices = AudioUtilities.GetSpeakers()\n",
    "    interface = devices.Activate(\n",
    "        IAudioEndpointVolume._iid_, CLSCTX_ALL, None)\n",
    "    volume = cast(interface, POINTER(IAudioEndpointVolume))\n",
    "    \n",
    "    volume_range = volume.GetVolumeRange()\n",
    "    min_volume = volume_range[0]\n",
    "    max_volume = volume_range[1]\n",
    "\n",
    "    # new_volume = max(0.0, volume_level - 0.1) \n",
    "    \n",
    "    # Calculate the volume level within the range\n",
    "    adjusted_volume = min_volume + (max_volume - min_volume) * volume_level\n",
    "    \n",
    "    # Set the adjusted volume level\n",
    "    volume.SetMasterVolumeLevel(adjusted_volume, None)\n",
    "    print(\"Volume : \"+ str(volume.GetMasterVolumeLevelScalar()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    try:\n",
    "        # devices = AudioUtilities.GetSpeakers()\n",
    "        \n",
    "        # Display available devices\n",
    "        # for i, device in enumerate(devices):\n",
    "        #     print(f\"{i}: {device.FriendlyName}\")\n",
    "        \n",
    "        # device_index = int(input(\"Enter the device index you want to control: \"))\n",
    "        volume_input = float(input(\"Enter the desired volume level (0.0 to 1.0): \"))\n",
    "        \n",
    "        if 0 <= volume_input <= 1.0:\n",
    "            # set_volume(devices[device_index], volume_input)\n",
    "            set_volume( volume_input)\n",
    "\n",
    "            print(\"Volume set successfully.\")\n",
    "        else:\n",
    "            print(\"Invalid device index or volume level.\")\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", str(e))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Volume function to percent input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ctypes import cast, POINTER\n",
    "from comtypes import CLSCTX_ALL\n",
    "from pycaw.pycaw import AudioUtilities, IAudioEndpointVolume\n",
    "\n",
    "def SetVolumePercent(percent_input):\n",
    "\n",
    "            # percent_input = 50\n",
    "    min_range_volume = 0.7\n",
    "    max_range_volume = 1.0\n",
    "    devices = AudioUtilities.GetSpeakers()\n",
    "    interface = devices.Activate(   IAudioEndpointVolume._iid_, CLSCTX_ALL, None)\n",
    "    volume = cast(interface, POINTER(IAudioEndpointVolume))\n",
    "    if(percent_input != 0):\n",
    "\n",
    "\n",
    "        volume_range = volume.GetVolumeRange()\n",
    "        min_volume = volume_range[0]\n",
    "        max_volume = volume_range[1]\n",
    "\n",
    "        # print(volume_range)\n",
    "\n",
    "        scaled_result = min_range_volume + (max_range_volume - min_range_volume) * (percent_input / 100.0)\n",
    "        # print(scaled_result)\n",
    "        adjusted_volume = min_volume + (max_volume - min_volume) * scaled_result\n",
    "        # print(adjusted_volume)\n",
    "        volume.SetMasterVolumeLevel(adjusted_volume, None)\n",
    "        # print(\"Volume : \"+ str(volume.GetMasterVolumeLevelScalar()))\n",
    "    else:\n",
    "        volume.SetMasterVolumeLevel(-63, None)\n",
    "        # print(\"Volume : \"+ str(volume.GetMasterVolumeLevelScalar()))\n",
    "\n",
    "\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SetVolumePercent(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hand control Up volume number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# MediaPipe hand detection module\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m mp_drawing \u001b[39m=\u001b[39m mp\u001b[39m.\u001b[39msolutions\u001b[39m.\u001b[39mdrawing_utils\n\u001b[0;32m      3\u001b[0m mp_hands \u001b[39m=\u001b[39m mp\u001b[39m.\u001b[39msolutions\u001b[39m.\u001b[39mhands\n\u001b[0;32m      5\u001b[0m \u001b[39m# OpenCV video capture\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mp' is not defined"
     ]
    }
   ],
   "source": [
    "# MediaPipe hand detection module\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "# OpenCV video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "# Create a hands object\n",
    "with mp_hands.Hands(\n",
    "    static_image_mode=False,\n",
    "    max_num_hands=2,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5) as hands:\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Flip the frame horizontally\n",
    "        frame = cv2.flip(frame, 1)\n",
    "\n",
    "        # Process the frame with MediaPipe\n",
    "        results = hands.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                # Get the bounding box coordinates\n",
    "                x_min = min(lm.x for lm in hand_landmarks.landmark)\n",
    "                x_max = max(lm.x for lm in hand_landmarks.landmark)\n",
    "                y_min = min(lm.y for lm in hand_landmarks.landmark)\n",
    "                y_max = max(lm.y for lm in hand_landmarks.landmark)\n",
    "\n",
    "                # Calculate the width and height of the bounding box\n",
    "                width = x_max - x_min\n",
    "                height = y_max - y_min\n",
    "\n",
    "                # Consider only the right hand based on the bounding box\n",
    "                if width > 0.3 and height > 0.3:\n",
    "\n",
    "                    # Get the landmarks of the thumb and index finger\n",
    "                    thumb_tip = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP]\n",
    "                    index_finger_tip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "\n",
    "                    # Calculate the Euclidean distance between thumb and index finger\n",
    "                    distance = math.sqrt(\n",
    "                        (thumb_tip.x - index_finger_tip.x) ** 2 + (thumb_tip.y - index_finger_tip.y) ** 2)\n",
    "\n",
    "                    # Map the distance to volume range (0-100)\n",
    "                    volume = int((distance * 100) / 0.3)  # Adjust the scaling factor as needed\n",
    "\n",
    "                    # Set the system volume\n",
    "                    SetVolumePercent(volume)\n",
    "\n",
    "                    # Display the volume level on the frame\n",
    "                    cv2.putText(frame, f\"Volume: {volume}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
    "\n",
    "                    # Draw lines between fingers\n",
    "                    cv2.line(frame, (int(thumb_tip.x * frame.shape[1]), int(thumb_tip.y * frame.shape[0])),\n",
    "                             (int(index_finger_tip.x * frame.shape[1]), int(index_finger_tip.y * frame.shape[0])),\n",
    "                             (0, 255, 0), 2)\n",
    "\n",
    "                    # Draw hand landmarks on the frame\n",
    "                    mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "        # Display the resulting frame\n",
    "        cv2.imshow('Finger Volume Control', frame)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Hand_Detection-GuvXzzGQ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
